<p><img src="/assets/images/template-matching/header-short.png" alt="Before-after image" />
&lt;aside class="sidebar__right"&gt;
&lt;nav class="toc" markdown="1"&gt;</p>
<header><h4 class="nav__title"><i class="fa fa-"></i> Table of Contents</h4></header>
<ul class="toc__menu" id="markdown-toc">
  <li><a href="#the-input-data">The Input Data</a></li>
  <li><a href="#geometric-transformation-and-coalescing-algorithm">Geometric Transformation and Coalescing Algorithm</a>    <ul>
      <li><a href="#transform">Transform</a></li>
      <li><a href="#coalesce">Coalesce</a></li>
    </ul>
  </li>
  <li><a href="#putting-it-all-together">Putting It All Together</a></li>
  <li><a href="#conclusion-and-takeaway">Conclusion and Takeaway</a>    <ul>
      <li><a href="#my-takeaway">My Takeaway</a></li>
    </ul>
  </li>
  <li><a href="#complete-code">Complete Code</a></li>
</ul>
<p>&lt;/nav&gt;
&lt;/aside&gt;
The problem we are trying to solve is find the exact locations of cells undergoing mitosis in histology images. These are the cells that are annotated with green arrows. In other words, given the <strong>Before</strong> image above, we want to extract data shown in <strong>After</strong>. </p>

<p>In <a href="https://tonyzhangnd.github.io/2017/07/Mitosis-Image-Processing-1.html">Part 1</a>, I have detailed how I used template matching in openCV to obtain bounding boxes on the arrows with 100% accuracy. In this post, I will describe my algorithm used to transform the bounding box information into the coordinates of the arrowheads. </p>

<h2 id="the-input-data">The Input Data</h2>
<p>We use the code in Part 1, but with one important change:</p>

<pre><code class="language-python">import numpy as np
import cv2
import os
from scipy import misc, ndimage
from multiprocessing import Pool
import pickle
import math
import re
import csv

PKL_DIR = {path to pickle files}
LOC_DIR = {path to final csv files}

{import functions from Part 1}

def match_and_pickle(img_name):
    """ Apply template matching to img_name in IMG_DIR, using
    tmpl{0...359}.png and mask{0...359}.png.
    
    Output: Coordinates of the top left corner of matching templates, 
    in the format [(deg, [points])], saved in img_name.pkl.
    """
    print('Matching img %s' %img_name)
    img_rgb = cv2.imread(os.path.join(STRIPPED_DIR, img_name))
    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)
    matches = []
    for deg in range(0, 360, MATCH_RES):
        tmpl = cv2.imread(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), 
            cv2.IMREAD_GRAYSCALE)
        mask = cv2.imread(os.path.join(MASK_DIR, 'mask%d.png' %deg), 
            cv2.IMREAD_GRAYSCALE)
        if tmpl is None or mask is None:
            print('Failed to match for tmpl %d.' %deg)
        else:
            w, h = tmpl.shape[::-1]
            res = cv2.matchTemplate(img_gray, tmpl, cv2.TM_SQDIFF, mask=mask)
            loc = np.where(res &lt; MATCH_THRESH)
            pts = zip(*loc[::-1])   #top left corners of arrow bounding box
            if len(pts)&gt;0:
                matches.append((deg, pts))
    file_name = os.path.join(PKL_DIR,
        "".join(img_name.split('_')[:-1])+'.pkl')  #eg M21.pkl
    with open(file_name,'wb') as f:
        pickle.dump(matches, f)
    return
</code></pre>
<p>Here, I replaced the function <code>match_and_draw()</code> from Part 1 with <code>match_and_pickle()</code>. The difference is that instead of drawing the bounding boxes the images, we save the location the arrows and their orientations as pickled data. </p>

<p>Recall that we have 360 arrow templates, one for each degree of orientation, with which we perform template matching. For each image, we save the data in the following Python tuple list format: \
<code>[(deg, [(x, y), ...]), ...]</code>,
where <code>deg</code> is the orientation of the template that matched, and <code>(x, y)</code> are the coordinates of the matching bounding box. Note that these are the positions of the top left corners of the bounding boxes.</p>

<p>I can visualize then the bounding boxes with the following code, which loads the pickle data generated by <code>match_and_pickle()</code> and draws the bounding boxes on a given image.</p>

<pre><code class="language-python">class Color_Iterator(object):
    colors = [(0,0,255), (255,0,0), (204,204,0)]
    i = 0

    def next(self):
        self.i += 1
        return self.colors[self.i % len(self.colors)]


CI = Color_Iterator()


def draw_from_pkl(img_name, output_path='./'):
    """ Draws bounding boxes on stripped ver of img_name with matches from
    img_name.pkl. 
    Saves output image in output_path.

    Example: draw_from_pkl(M21.jpg, './') draws boxes on M21_s.jpg, and 
    saves output as M21_r.jpg in the current directory.
    """
    img_name = ''.join(img_name.split('.')[:-1])+'_s.jpg'
    img_rgb = cv2.imread(os.path.join(STRIPPED_DIR, img_name))
    pkl_name = os.path.join(PKL_DIR,
        "".join(img_name.split('_')[:-1])+'.pkl')  #eg M21.pkl
    with open(pkl_name,'r') as f:
        matches = pickle.load(f)
    for (deg, pts) in matches:
        tmpl = cv2.imread(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), 
            cv2.IMREAD_GRAYSCALE)
        w, h = tmpl.shape[::-1]
        for pt in pts:
            cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), CI.next(), 1)
    img_name = "".join(img_name.split('_')[:-1])
    cv2.imwrite(os.path.join(output_path, img_name+'_r.jpg'), img_rgb)  #eg M21_r.jpg
</code></pre>

<p>The above code produces images that appear like so:</p>

<p><img src="/assets/images/template-matching/res_color box.jpg" alt="Bounding boxes with color" /> </p>

<p>Here, I used <code>Color_Iterator</code> to iterate the color of the boxes drawn. This is to highlight an important feature: <em>There are multiple matches for each arrow</em>. This is because two templates a degree apart may both match on the same arrow; or one template could match many times on the same arrow, each a few pixels apart. </p>

<p>This fact is important later on because it means that there is a many-to-one mapping from matches to arrows. Since we only want one point per arrow in our final output, we need to coalesce a bunch of matches per arrow into one single point.</p>

<h2 id="geometric-transformation-and-coalescing-algorithm">Geometric Transformation and Coalescing Algorithm</h2>

<h3 id="transform">Transform</h3>
<p>One important question is still unanswered. Currently, we only have information regarding the location of the top left corner of the bounding boxes. <strong>As such, how do we transform these points into the position of the arrowheads?</strong> With the orientation of the arrows retrieved from our matching algorithm, this can be done with simple trigonometry!</p>

<p><img src="/assets/images/template-matching/geometry.png" alt="Geometry" /></p>

<p>Consider the above schematic. The dashed box represents the bounding box on the arrow. <script type="math/tex">\alpha</script>, <script type="math/tex">(x, y)</script>, <script type="math/tex">width</script> and <script type="math/tex">height</script> are known quantities, where <script type="math/tex">\alpha</script> is the rotation of the matching template, and <script type="math/tex">width</script>, <script type="math/tex">height</script> are the dimensions of the bounding box.</p>

<p>The center of the bounding box <script type="math/tex">(cx, cy)</script>, which is also the center of the arrow, is:</p>

<script type="math/tex; mode=display">(cx, cy) = (x+\frac{width}{2}, y+\frac{height}{2})</script>

<p>Then, the quantities we are after, <script type="math/tex">(px, py)</script>, are:</p>

<script type="math/tex; mode=display">px = cx - l \cos(\alpha)</script>

<script type="math/tex; mode=display">py = cy + l \sin(\alpha)</script>

<p>where <script type="math/tex">l</script> is the practical pixel radius of the arrow. It is longer than the actual half-length of the arrows because we want <script type="math/tex">(px, py)</script> to be slightly ahead of the arrow tip.</p>

<p>Note that in this case, I have defined the negative x-axis to be zero degrees, and the angle increases anti-clockwise.</p>

<pre><code class="language-python">RADIUS = 42

def transform(matches):
    """ Transforms a list of (deg * coordinate list), where the coordinates
    are of the top-left corner of the tmpl bounding boxes, to a list containting
    the coordinates of the tips of the arrows.
    Returns the list of transformed coordinates.
    """
    tips = []
    for (deg, pts) in matches:
        tmpl = cv2.imread(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), 0)
        w, h = tmpl.shape[::-1]
        rad = math.radians(deg)
        for pt in pts:   #top left corner of arrow bounding box
            (cx, cy) = (pt[0]+w/2, pt[1]+h/2)  #center of the arrow
            tips.append((int(cx - RADIUS*math.cos(rad)), int(cy + RADIUS*math.sin(rad))))
    return tips
</code></pre>
<p>In the above code, </p>

<ul>
  <li>The parameter <code>matches</code> is the list generated by <code>match_and_picke()</code></li>
  <li><script type="math/tex">\alpha=</script> <code>deg</code></li>
  <li><script type="math/tex">(x, y)=</script> <code>pt</code></li>
  <li><script type="math/tex">width=</script> <code>w</code></li>
  <li><script type="math/tex">height=</script> <code>h</code></li>
  <li><script type="math/tex">l=</script> <code>RADIUS</code></li>
  <li><script type="math/tex">[(px, py), ...]=</script> <code>tips</code></li>
</ul>

<p>Plotting the list of <script type="math/tex">(px, py)</script> on the original image will give us something like this: </p>

<p><img src="/assets/images/template-matching/res_dup arrows.jpg" alt="After transformation" /></p>

<p>Again, if you observe closely, there are multiple points per arrow.</p>

<h3 id="coalesce">Coalesce</h3>
<p>To produce our final output, coalescing multiple points into one final point is straightforward: if two points <script type="math/tex">a</script> and <script type="math/tex">b</script> are within a certain distance, then <script type="math/tex">b</script> is a duplicate.</p>

<pre><code class="language-python">def coalesce(tips):
    """ Reduces points close to together in tips into one point.
    Returns the list of reduced points.
    """
    thresh = 7
    
    def not_distinct(p1, p2):
        (p1x, p1y) = p1
        (p2x, p2y) = p2
        return (p1x-p2x)**2 + (p1y-p2y)**2 &lt;= thresh**2 

    def update(pt, distinct_pts):
        for dpt in distinct_pts:
            if not_distinct(pt, dpt):
                return
        distinct_pts.append(pt)
        return

    if len(tips) &lt;= 1:
        return tips
    distinct_pts = []
    for pt in tips:
        update(pt, distinct_pts)
    return distinct_pts
</code></pre>

<p>Here, the input <code>tips</code> is the list of <script type="math/tex">(px, py)</script> for all the arrows in an image. <code>thresh</code> is the pixel distance between two points for them to be considered duplicates. The return value <code>distinct_points</code> is then the final set of points in an image, with one point per arrow. This algorithm runs in <script type="math/tex">O(n^2)</script>.</p>

<p>One may imagine that coalescing can be improved to <script type="math/tex">O(n)</script> if we first sort the input list and use the ‘runner technique’. Then we would only need a ‘fast’ pointer to look ahead and find the next distinct point, then add the ‘slow’ pointer to our output and jump the ‘slow’ pointer to the ‘fast’ pointer. But this requires the precondition that no pair of arrows point to <em>similar</em> <script type="math/tex">x</script> <em>or</em> <script type="math/tex">y</script> coordinates, which is something we <em>cannot</em> guarantee. </p>

<h2 id="putting-it-all-together">Putting It All Together</h2>

<p>The following function <code>transform_and_coalesce()</code> is a wrapper that performs <code>transform()</code> and <code>coalesce()</code> on data loaded from a pickle file and then writes the final output into a csv file. The first line is the number of points in the image, followed by one point per line.</p>

<pre><code class="language-python">def transform_and_coalesce(img_name):
    """ Applies transform() and coalesce() on data from the pickle file
    of img_name. E.g. M21.pkl from PKL_DIR
    Saves output as a csv file. E.g. M21.csv
    """
    print('Transforming for image %s' %img_name)
    pkl_name = "".join(img_name.split('.')[:-1])+'.pkl'  #eg M21.pkl
    try:
        with open(os.path.join(PKL_DIR, pkl_name),'r') as f:
            matches = pickle.load(f)
    except IOError:
        print('Failed to transform img %s. pkl file not found.' %img_name)
        return
    tips = coalesce(transform(matches))
    #Write into csv
    csv_name = ''.join(img_name.split('.')[:-1])+'.csv'
    with open(os.path.join(LOC_DIR, csv_name),'w') as f:
        wr = csv.writer(f)
        wr.writerow([len(tips)])  #1st line is number of arrows
        for pt in tips:
            wr.writerow(pt)
    return
</code></pre>

<p>To make sure we get the correct result <code>plot()</code> draws the points on the image by loading the points from the csv file we created.</p>

<pre><code class="language-python">def plot(img_name, output_path='plots'):
    print('Plotting image %s' %img_name)
    img_rgb = cv2.imread(os.path.join(IMG_DIR, img_name))
    csv_name = "".join(img_name.split('.')[:-1])+'.csv'  #eg M21.pkl
    try:
        with open(os.path.join(LOC_DIR, csv_name),'r') as f:
            rd = csv.reader(f)
            num = int(rd.next()[0])
            for i in range(num):
                pt_str = rd.next()
                pt = (int(pt_str[0]), int(pt_str[1]))
                cv2.drawMarker(img_rgb, pt, CI.next(), cv2.MARKER_CROSS, 20, 4)
            cv2.putText(img_rgb, str(num), (10,800), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255),2,cv2.LINE_AA)
    except IOError:
        print('Failed to plot img %s. pkl file not found.' %img_name)
        return
    out_name = ''.join(img_name.split('.')[:-1])+'_p.jpg'
    out = os.path.join(output_path, out_name)
    cv2.imwrite(out, img_rgb)  #eg M21_p.jpg
</code></pre>

<p>Here is an example of the final result:
<img src="/assets/images/template-matching/res_final.jpg" alt="Final plot" /></p>

<p>We can see that we now only have one point for each arrow, and we are done! </p>

<p>The full code complete with some additional functions for bulk processing are at the end of this page.</p>

<h2 id="conclusion-and-takeaway">Conclusion and Takeaway</h2>
<p>There are some design choices in my program that I would like to address. </p>

<p>First, it is possible, and indeed more efficient, to do away with the pickling and directly pass the output of <code>match()</code> into <code>transform_and_coalesce()</code>. However, I chose to have an intermediate pickling stage for the sake of easier debugging. It allows me to draw plots from the pickled data to make sure <code>match()</code> works as it should. It also allows me to test <code>transform_and_coalesce()</code> without needing to run <code>match()</code> over and over again. </p>

<p>Second, my supervisor asked me why I have individual final csv files for each image, instead of saving the data for all my images in one big csv. The answer is that I need the data for machine learning applications later on, but I will probably only need data for a few images at any given time. So separating the csv’s mean less slicing and dicing later on.</p>

<h3 id="my-takeaway">My Takeaway</h3>
<p>Working on this image processing project was something I was really excited about. Through this process, I came to realize what motivates me. I am excited by stuff that I don’t know how to do, stuff that I feel completely clueless about. At times, work goes like this:</p>

<ol>
  <li>Supervisor: Here’s a problem, do you know how to solve it?</li>
  <li>Me: I have absolutely no clue, but that means I will get it done.</li>
  <li>Me a few days later: It is done!</li>
</ol>

<p>On the other hand, I’m less excited about problems where I know there are standard tools and a standard solutions, because then it is grunt work, and there is less to learn from it. </p>

<p>The more clueless I am, the more I want to get my hands on the problem. It is beyond the excitement of learning a new technology or skill. It is the passion of doing something where there is no known recipe, and trying to find out if it can even be done!</p>

<h2 id="complete-code">Complete Code</h2>

<pre><code class="language-python">import numpy as np
import cv2
import os
from scipy import misc, ndimage
from multiprocessing import Pool
import pickle
import math
import re
import csv

IMG_DIR = {path to original images}
STRIPPED_DIR = {path to save stripped images}
TMPL_DIR = {path to templates}
MASK_DIR = {path to masks}
PKL_DIR = {path to pickle files}
LOC_DIR = {path to final csv files}

GREEN = np.array([89, 248, 89])
MATCH_THRESH = 11
MATCH_RES = 1  #specifies degree-interval at which to match
#Match thresholds and resolution were empirically tuned
RADIUS = 42  #Half the length of the arrow in pixels


class Color_Iterator(object):
    colors = [(0,0,255), (255,0,0), (204,204,0)]
    i = 0

    def next(self):
        self.i += 1
        return self.colors[self.i % len(self.colors)]


CI = Color_Iterator()


def strip(img_name):
    """ Removes background from img_name in IMG_DIR, leaving only green arrows.
    Saves stripped image in STRIPPED_DIR, as img_name's'.jpg 
    """
    print('Stripping img %s' %img_name)
    arr = misc.imread(os.path.join(IMG_DIR, img_name))
    (x_size, y_size, z_size) = arr.shape
    for x in range(x_size):
        for y in range(y_size):
            if not np.array_equal(arr[x, y], GREEN):
                arr[x, y] = np.array([0, 0, 0])
    img_name = "".join(img_name.split('.')[:-1])
    misc.imsave(os.path.join(STRIPPED_DIR, img_name+'_s.jpg'), arr)  #eg M21_s.jpg
    return


def strip_all(num_processes=2):
    """ Applies strip() to images of name M{start..start+num_images-1}.jpg.

    This method uses multiprocessing:
    num_processes -- the number of parallel processes to spawn for this task.
    (default 2)
    """
    imgs = [i for i in os.listdir(IMG_DIR) if re.match(r'M[0-9]*.jpg', i)]
    print('Stripping background from %d images' %len(imgs))
    pool = Pool(num_processes)
    pool.map(strip, imgs)
    pool.close()
    pool.join()
    print('Done')
    return


def make_templates(base='base_short.png'):
    """ Makes templates for rotational-deg=0...359 from base in TMPL_DIR.
    Saves rotated templates as tmpl{deg}.png in TMPL_DIR
    """
    try:
        base = misc.imread(os.path.join(TMPL_DIR, base))
    except IOError:
        print('Failed to make templates. Base template is not found')
        return
    for deg in range(360):
        tmpl = ndimage.rotate(base, deg)
        misc.imsave(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), tmpl)
    return


def make_masks():
    """ Makes masks from tmpl{0...359}.png in TMPL_DIR.
    Saves masks as mask{0...359}.png in MASK_DIR
    """
    for deg in range(360):
        tmpl = cv2.imread(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), 
            cv2.IMREAD_GRAYSCALE)
        if tmpl is None:
            print('Failed to make mask {0}. tmpl{0}.png is not found.'.
                format(deg))
        else:
            ret2, mask = cv2.threshold(tmpl, 0, 255, 
                cv2.THRESH_BINARY+cv2.THRESH_OTSU)
            cv2.imwrite(os.path.join(MASK_DIR, 'mask%d.png' %deg), mask)
    return



def match_and_pickle(img_name):
    """ Apply template matching to img_name in IMG_DIR, using
    tmpl{0...359}.png and mask{0...359}.png.
    
    Output: Coordinates of the top left corner of matching templates, 
    in the format [(deg, [points])], saved in img_name.pkl.
    """
    print('Matching img %s' %img_name)
    img_rgb = cv2.imread(os.path.join(STRIPPED_DIR, img_name))
    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)
    matches = []
    for deg in range(0, 360, MATCH_RES):
        tmpl = cv2.imread(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), 
            cv2.IMREAD_GRAYSCALE)
        mask = cv2.imread(os.path.join(MASK_DIR, 'mask%d.png' %deg), 
            cv2.IMREAD_GRAYSCALE)
        if tmpl is None or mask is None:
            print('Failed to match for tmpl %d.' %deg)
        else:
            w, h = tmpl.shape[::-1]
            res = cv2.matchTemplate(img_gray, tmpl, cv2.TM_SQDIFF, mask=mask)
            loc = np.where(res &lt; MATCH_THRESH)
            pts = zip(*loc[::-1])   #top left corners of arrow bounding box
            if len(pts)&gt;0:
                matches.append((deg, pts))
    file_name = os.path.join(PKL_DIR,
        "".join(img_name.split('_')[:-1])+'.pkl')  #eg M21.pkl
    with open(file_name,'wb') as f:
        pickle.dump(matches, f)
    return


def match_all(num_processes=2):
    """ Applies match() to images of name M{start ... start+num_images-1}s.jpg.

    This method uses multiprocessing:
    num_processes -- the number of parallel processes to spawn for this task.
    (default 2)
    """
    imgs = [i for i in os.listdir(STRIPPED_DIR) if re.match(r'M[0-9]*_s.jpg', i)]
    print('Matching %d images' %len(imgs))
    pool = Pool(num_processes)
    pool.map(match_and_pickle, imgs)
    pool.close()
    pool.join()
    print('Done')
    return


def draw_from_pkl(img_name, output_path='./'):
    """ Draws bounding boxes on stripped ver of img_name with matches from
    img_name.pkl. 
    Saves output image in output_path.

    Example: draw_from_pkl(M21.jpg, './') draws boxes on M21_s.jpg, and 
    saves output as M21_r.jpg in the current directory.
    """
    img_name = ''.join(img_name.split('.')[:-1])+'_s.jpg'
    img_rgb = cv2.imread(os.path.join(STRIPPED_DIR, img_name))
    pkl_name = os.path.join(PKL_DIR,
        "".join(img_name.split('_')[:-1])+'.pkl')  #eg M21.pkl
    with open(pkl_name,'r') as f:
        matches = pickle.load(f)
    for (deg, pts) in matches:
        tmpl = cv2.imread(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), 
            cv2.IMREAD_GRAYSCALE)
        w, h = tmpl.shape[::-1]
        for pt in pts:
            cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), CI.next(), 1)
    img_name = "".join(img_name.split('_')[:-1])
    cv2.imwrite(os.path.join(output_path, img_name+'_r.jpg'), img_rgb)  #eg M21_r.jpg


def transform(matches):
    """ Transforms a list of (deg * coordinate list), where the coordinates
    are of the top-left corner of the tmpl bounding boxes, to a list containting
    the coordinates of the tips of the arrows.
    Returns the list of transformed coordinates.
    """
    tips = []
    for (deg, pts) in matches:
        tmpl = cv2.imread(os.path.join(TMPL_DIR, 'tmpl%d.png' %deg), 0)
        w, h = tmpl.shape[::-1]
        rad = math.radians(deg)
        for pt in pts:   #top left corner of arrow bounding box
            (cx, cy) = (pt[0]+w/2, pt[1]+h/2)  #center of the arrow
            tips.append((int(cx - RADIUS*math.cos(rad)), int(cy + RADIUS*math.sin(rad))))
    return tips


def coalesce(tips):
    """ Reduces points close to together in tips into one point.
    Returns the list of reduced points.
    """
    thresh = 7
    
    def not_distinct(p1, p2):
        (p1x, p1y) = p1
        (p2x, p2y) = p2
        return (p1x-p2x)**2 + (p1y-p2y)**2 &lt;= thresh**2 

    def update(pt, distinct_pts):
        for dpt in distinct_pts:
            if not_distinct(pt, dpt):
                return
        distinct_pts.append(pt)
        return

    if len(tips) &lt;= 1:
        return tips
    distinct_pts = []
    for pt in tips:
        update(pt, distinct_pts)
    return distinct_pts


def transform_and_coalesce(img_name):
    """ Applies transform() and coalesce() on data from the pickle file
    of img_name. E.g. M21.pkl from PKL_DIR
    Saves output as a csv file. E.g. M21.csv
    """
    print('Transforming for image %s' %img_name)
    pkl_name = "".join(img_name.split('.')[:-1])+'.pkl'  #eg M21.pkl
    try:
        with open(os.path.join(PKL_DIR, pkl_name),'r') as f:
            matches = pickle.load(f)
    except IOError:
        print('Failed to transform img %s. pkl file not found.' %img_name)
        return
    tips = coalesce(transform(matches))
    #Write into csv
    csv_name = ''.join(img_name.split('.')[:-1])+'.csv'
    with open(os.path.join(LOC_DIR, csv_name),'w') as f:
        wr = csv.writer(f)
        wr.writerow([len(tips)])  #1st line is number of arrows
        for pt in tips:
            wr.writerow(pt)
    return
        

def transform_and_coalesce_all(num_processes=2):
    """Applies transform_and_coalesce() to images of name 
    M{start ... start+num_images-1}s.jpg.

    This method uses multiprocessing:
    num_processes -- the number of parallel processes to spawn for this task.
    (default 2)
    """
    imgs = [i for i in os.listdir(IMG_DIR) if re.match(r'M[0-9]*.jpg', i)]
    print('Transforming %d images' %len(imgs))
    pool = Pool(num_processes)
    pool.map(transform_and_coalesce, imgs)
    pool.close()
    pool.join()
    print('Done')
    return


def plot(img_name, output_path='plots'):
    print('Plotting image %s' %img_name)
    img_rgb = cv2.imread(os.path.join(IMG_DIR, img_name))
    csv_name = "".join(img_name.split('.')[:-1])+'.csv'  #eg M21.pkl
    try:
        with open(os.path.join(LOC_DIR, csv_name),'r') as f:
            rd = csv.reader(f)
            num = int(rd.next()[0])
            for i in range(num):
                pt_str = rd.next()
                pt = (int(pt_str[0]), int(pt_str[1]))
                cv2.drawMarker(img_rgb, pt, CI.next(), cv2.MARKER_CROSS, 20, 4)
            cv2.putText(img_rgb, str(num), (10,800), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255),2,cv2.LINE_AA)
    except IOError:
        print('Failed to plot img %s. pkl file not found.' %img_name)
        return
    out_name = ''.join(img_name.split('.')[:-1])+'_p.jpg'
    out = os.path.join(output_path, out_name)
    cv2.imwrite(out, img_rgb)  #eg M21_p.jpg


def plot_label(img_name):
    print('Plotting image %s' %img_name)
    csv_name = "".join(img_name.split('.')[:-1])+'.csv'  #eg M21.pkl
    img_name = ''.join(img_name.split('.')[:-1])+'_s.jpg'
    img_rgb = cv2.imread(os.path.join(STRIPPED_DIR, img_name))
    try:
        with open(os.path.join(LOC_DIR, csv_name),'r') as f:
            rd = csv.reader(f)
            num = int(rd.next()[0])
            for i in range(num):
                pt_str = rd.next()
                (x, y) = (int(pt_str[0]), int(pt_str[1]))
                cv2.drawMarker(img_rgb, (x, y), (0,0,255), cv2.MARKER_CROSS, 20, 4)
                cv2.putText(img_rgb, str((x, y)), (x+10, y+70), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),2,cv2.LINE_AA)
            cv2.putText(img_rgb, str(num), (10,800), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255),2,cv2.LINE_AA)
    except IOError:
        print('Failed to plot img %s. pkl file not found.' %img_name)
        return
    out = ''.join(img_name.split('_')[:-1])+'_p.jpg'
    cv2.imwrite(out, img_rgb)  #eg M21_p.jpg


def plot_all(num_processes=2):
    imgs = [i for i in os.listdir(IMG_DIR) if re.match(r'M[0-9]*.jpg', i)]
    print('Plotting %d images' %len(imgs))
    pool = Pool(num_processes)
    pool.map(plot, imgs)
    pool.close()
    pool.join()
    print('Done')
    return
</code></pre>
